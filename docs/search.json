[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hello, and welcome to my portfolio website! My name is Lynn Serizawa, and I am thrilled to have the opportunity to introduce myself and showcase my work to you.\nI am currently a research data analyst with a passion for uncovering insights and hidden patterns to develop solutions to make healthcare more accessible, efficient, and accurate. I graduated from New York University (NYU) in May 2022, where I double majored in mathematics and philosophy. This unique combination of analytical thinking and critical reasoning has shaped my approach to data analysis and problem-solving.\nMy journey into the world of data science began during the pandemic when I took a gap year. Eager to expand my knowledge and skills, I immersed myself in online resources to learn the fundamentals of data science. Upon returning to NYU to complete my senior year, I delved deeper into the field by taking classes such as Probability and Statistics and Linear and Nonlinear Optimization, solidifying my foundation in key data science concepts.\nCurrently, I serve as a research data analyst at the Immune Tolerance Network at the University of California, San Francisco, where I contribute to various projects involving logistics and data cleaning and reporting. In this role, I have gained hands-on experience in manipulating and analyzing large datasets, implementing data cleaning scripts, and generating crucial reports to drive informed decision-making.\nPrior to my work at the Immune Tolerance Network, I honed my data analysis skills as a lab research assistant at the Nusse Lab at Stanford University. There, I conducted data analysis on data from experiments I ran, employing statistical techniques to extract meaningful results. Additionally, I worked in the Barres Lab at Stanford University, utilizing ImageJ and MATLAB to analyze neuron images and measure their axon-to-myelin ratio, further refining my expertise in image analysis.\nI am deeply passionate about the power of data and its potential to drive innovation and create positive change. I thrive in interdisciplinary environments, where I can collaborate with experts from diverse fields to tackle complex problems and unlock data-driven solutions.\nThroughout my career, I continuously seek opportunities to expand my knowledge and stay up to date with the latest advancements in data science. I am particularly interested in exploring machine learning, data visualization, and image analysis, as I believe these areas hold tremendous potential for innovation.\nThank you for visiting my portfolio website, and I invite you to explore my projects. I am excited about the possibility of collaborating on future endeavors and leveraging the power of data to make a meaningful impact in the world.\nFeel free to contact me through LinkedIn!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Lynn Serizawa",
    "section": "",
    "text": "Hey! My name is Lynn, and I am currently a research data analyst with the Immune Tolerance Network located in University of California, San Francisco (UCSF)."
  },
  {
    "objectID": "julia.html",
    "href": "julia.html",
    "title": "Julia Code",
    "section": "",
    "text": "Coming soon!"
  },
  {
    "objectID": "matlab/ballistic/ballistic.html",
    "href": "matlab/ballistic/ballistic.html",
    "title": "Ballistics Calculator",
    "section": "",
    "text": "Summary:\nIn this project, I created a script that calculates and draws the path a projectile takes. It takes into account variables such as the Magnus force and the Coriolis effect. Below is an example of what is produced when the script is run.\n\nClick here for the GitHub repository."
  },
  {
    "objectID": "matlab/convoy/convoy.html",
    "href": "matlab/convoy/convoy.html",
    "title": "Convoy/Parade Traffic Simulation",
    "section": "",
    "text": "Summary:\nFor this project, I worked with a partner to create a MATLAB script that can simulate how a convoy, parade, or any other situation where entities travel together in an organized fashion, changes based on their protocol (e.g., keep at least 100 meters between each vehicle) or environmental changes (e.g., turns, flat tire).\nTo model the path, we converted a two-dimensional map into a one-dimensional line. On our line, dots represent individuals (e.g., vehicle, parade float) and asterisks indicate places on the path where there are obstacles or events that might alter the progress of the convoy (e.g., turns, slowing down to take pictures (don’t do this!)).\nBelow is an example of what the script can produce. In this scenario, the convoy experiences potholes at the asterisks, and their protocol is to maintain a certain distance between vehicles.\n\nClick here to get to the GitHub repo that has the script itself."
  },
  {
    "objectID": "matlab/IMM/imm.html",
    "href": "matlab/IMM/imm.html",
    "title": "Code Written for MATH-UA 251 Introduction to Mathematical Modeling",
    "section": "",
    "text": "Below are MATLAB scripts I wrote for a class at NYU I took called MATH-UA 251 Introduction to Mathematical Modeling. My professor was Dr. Aref Hashemi."
  },
  {
    "objectID": "matlab/IMM/imm.html#freezing-orange-emissivity",
    "href": "matlab/IMM/imm.html#freezing-orange-emissivity",
    "title": "Code Written for MATH-UA 251 Introduction to Mathematical Modeling",
    "section": "Freezing Orange Emissivity",
    "text": "Freezing Orange Emissivity\nThis file graphs the temperature of fruit as it freezes despite the ambient air being above 0 degrees celsius. Below is an example: \nScript that generates the graph above."
  },
  {
    "objectID": "matlab/IMM/imm.html#charged-particle-under-influence-of-drag-force-and-unidirectional-potential",
    "href": "matlab/IMM/imm.html#charged-particle-under-influence-of-drag-force-and-unidirectional-potential",
    "title": "Code Written for MATH-UA 251 Introduction to Mathematical Modeling",
    "section": "Charged Particle Under Influence of Drag Force and Unidirectional Potential",
    "text": "Charged Particle Under Influence of Drag Force and Unidirectional Potential\nThis file simulates the movement of a particle whose movement is affected by a drag force and a unidirectional potential. Two methods are compared: Euler’s method and the perturbation method. Below is a graph that shows how the particle’s velocity changes using the two different methods. \nScript that plots the velocity of the particle using both the Euler’s method and the perturbation method."
  },
  {
    "objectID": "matlab/IMM/imm.html#pendulum-report",
    "href": "matlab/IMM/imm.html#pendulum-report",
    "title": "Code Written for MATH-UA 251 Introduction to Mathematical Modeling",
    "section": "Pendulum Report",
    "text": "Pendulum Report\nThe final project for this class was to simulate the movement of a pendulum on a string or a rod, with or without air resistance.\n\nWrite-up/Report.\nCode used to determine an appropriate timestep for the Forward Euler Method.\nScript that simulates the movement of a pendulum on a string without air resistance.\nScript that simulates the movement of a pendulum on a string with air resistance.\nScript that simulates the movement of a pendulum on a rod without air resistance.\nScript that simulates the movement of a pendulum on a rod with air resistance."
  },
  {
    "objectID": "matlab/SpecTopProj1/spec1.html",
    "href": "matlab/SpecTopProj1/spec1.html",
    "title": "Simulation of Elastic Textile as System of Springs",
    "section": "",
    "text": "Summary:\nThis project aims to simulate an object falling onto a trampoline or fabric. The trampoline/fabric is modeled as a system of springs. Below is a video of the end result:\n\nClick here for the report for the project.\nClick here to get to the GitHub repo that has the script itself.\nClick here for the presentation I made for the project, which I presented to the class."
  },
  {
    "objectID": "matlab.html",
    "href": "matlab.html",
    "title": "MATLAB Code",
    "section": "",
    "text": "Note: This website is built using Quarto. The platform supports Python, R, Julia, and Observable Javascript. It does not support MATLAB at this time. One solution to incorporate MATLAB is to use the MATLAB kernel in Jupyter. However, I cannot use the kernel because Windows (the system I use) is not supported. Therefore, to run the scripts, please download them from the GitHub link, then run it on your installation of MATLAB.\nConvoy/Parade Traffic Simulation\nTrampoline Simulation as a Network of Springs\nBallistics Calculator\nMATLAB Code from MATH-UA 251 Intro to Mathematical Modeling."
  },
  {
    "objectID": "python/832-check/compare-dsource.html",
    "href": "python/832-check/compare-dsource.html",
    "title": "Confirming Which Samples are in a Sample Tracking System, Participant Tracker, or a Biobank",
    "section": "",
    "text": "This script checks whether samples in one data source are present in the other data sources. This script pulls data from a sample tracking system through an SQL connection, and reads two Excel spreadsheets. Each sheet has at least the following columns:\n\nParticipant\nVisit Number\nVisit Date\n\nThe data for the purposes of demonstrating what the script does is included.\nStart by importing packages. Pandas will be used to read the spreadsheets, data from SQL queries, and create/manage dataframes that will be used to export a spreadsheet with the results. pyodbc will be used to access the SQL server. os will be used to find the files in the current directory (the spreadsheets from the participant tracker and biobank). calendar will be used to get a list of month names and abbreviations. It will also be used to limit the rows that result from the SQL query. This is because the spreadsheets are sent to us monthly, while the sample tracking system is essentially a real-time record. Without limiting the SQL query to the dates that the spreadsheets reflect, there would be many samples that are in the sample tracking system, but are not in the participant tracker or the biobank, simply due to the sources not being synced:\n\n# Import Packages\nimport pandas as pd\nimport pyodbc\nimport os\nimport calendar\n\nWe are comparing three data sources: our Specimen Tracking System, a BioBank, and an enrollment tracker. We can access the first source directly (i.e., we can pull information from it whenever we want). On the other hand, we are sent spreadsheets from the last two data sources at regular intervals. Once I receive these files, I place them in the same working directory as this script. However, I do not want to copy-paste the filename every time this script is run. The following finds the spreadsheet filenames by finding the strings “BCCHB” (the biobank) or “VisitEnrollmentData” in the filename:\n\n# Filenames for the biobank and visit enrollment sheets\nbbFN=\"\"\nveFN=\"\"\nfileList=os.listdir(os.getcwd()) # Get filenames for all files in the current working directory\nfor k in fileList: # For each file in the list...\n    if \"biobank\" in k: # If this is in the filename...\n        bbFN=k # This is the biobank sheet filename\n    elif \"VisitEnrollmentData\" in k: # If this is in the filename...\n        veFN=k # This is the visit enrollment filename\n    else:\n        continue\n\nThen, pandas reads the spreadsheets:\n\n# Read the sheets\nbiobank=pd.read_excel(bbFN)\nvisitenroll=pd.read_excel(veFN)\n\n\nprint(biobank)\n\n      PPID Event Label\n0    Alpha          V1\n1    Alpha          V2\n2    Bravo          V2\n3  Charlie          V4\n\n\n\nprint(visitenroll)\n\n  ParticipantID  Visit N\n0         Alpha        1\n1         Alpha        2\n2         Bravo        1\n3       Charlie        3\n\n\nSince the spreadsheets are sent to us monthly, I need to know the latest date the sheets have records for. These dates are in the filename. I only need to get the date from one filename since they are sent to us at the same time. To do so, I will use the filename from the visit enrollment tracker. The tracker’s filename comes in the following format:\nITNXXXYY_VisitEnrollmentData_MMM DD_YYYY.xlsx\nWhere X is the study number, Y is the study type, and M,D, and Y are month, day, and year, respectively.\nTo get this information, I remove characters that are not related to the date, then I convert the text representation of the date into an integer:\n\n# Extact date from the filename\nfilename=veFN\nfilename=filename.replace(\"demo_VisitEnrollmentData_\",\"\") # Remove this part\nfilename=filename.replace(\".xlsx\",\"\") # Remove this part\nfilename=filename.replace(\"_\",\" \") # Turn every underscore into a space\ndateparts=filename.split() # Split the string into space\nif len(dateparts[0])&gt;3: # Abbreviations are 3 chars long, so if its longer, then we need a dictionary with the full month names\n    mo2num={month: index for index, month in enumerate(calendar.month_name) if month}\nelse: # If the abbreviation is less than or equal to 3 chars long, then we use the abbreviations\n    mo2num={month: index for index, month in enumerate(calendar.month_abbr) if month}\ndateparts[0]=str(mo2num[dateparts[0]]) # Turn the month name into an integer representation\n\nprint(dateparts)\n\n['5', '31', '2023']\n\n\nI will start with the visit enrollment sheet: I start by only selecting the relevant columns. Then, I create a column that combines the participant ID and visit number that we will use as a primary key. Lastly, a column is created that has the source of the data (e.g., visit enrollment sheet):\n\n### VISIT ENROLLMENT ###\n# Keep only the relevant columns\nvisitenroll=visitenroll[[\"ParticipantID\",\"Visit N\"]]\n\n# Make a copy\nvepv=visitenroll.copy()\n\n# Turn the participant and Visit N columns into the string datatype\nvepv[\"ParticipantID\"]=vepv[\"ParticipantID\"].astype(str)\nvepv[\"Visit N\"]=vepv[\"Visit N\"].astype(str)\n\n# Create a column that combines the participant ID with the visit number\nvepv[\"PartVis\"]=vepv[\"ParticipantID\"]+\"-\"+vepv[\"Visit N\"]\n\n# Make a column that shows the source of the rows\nvepv[\"Source\"]=\"Visit Enrollment\"\n\nprint(vepv)\n\n  ParticipantID Visit N    PartVis            Source\n0         Alpha       1    Alpha-1  Visit Enrollment\n1         Alpha       2    Alpha-2  Visit Enrollment\n2         Bravo       1    Bravo-1  Visit Enrollment\n3       Charlie       3  Charlie-3  Visit Enrollment\n\n\nI do the same for the biobank file:\n\n### BIOBANK ###\n# Keep only the relevant columns\nbiobank=biobank[[\"PPID\",\"Event Label\"]]\n\n# Make a copy\nbbpv=biobank.copy()\n\n# Create a function that give us the visit number from the format V##\ndef visnum(eventlabel):\n    return eventlabel[1:]\n\n# Apply it to the biobank sheet so that we get the integer representation of the visit\nbbpv[\"visit\"]=bbpv.apply(lambda x: visnum(x[\"Event Label\"]),axis=1)\n\n# Turn the participant and visit columns into the string datatypes\nbbpv[\"PPID\"]=bbpv[\"PPID\"].astype(str)\nbbpv[\"visit\"]=bbpv[\"visit\"].astype(str)\n\n# Create a column that combines the participant ID with the visit number\nbbpv[\"PartVis\"]=bbpv[\"PPID\"]+\"-\"+bbpv[\"visit\"]\n\n# Make a column that shows the source of the rows\nbbpv[\"Source\"]=\"Biobank\"\n\nprint(bbpv)\n\n      PPID Event Label visit    PartVis   Source\n0    Alpha          V1     1    Alpha-1  Biobank\n1    Alpha          V2     2    Alpha-2  Biobank\n2    Bravo          V2     2    Bravo-2  Biobank\n3  Charlie          V4     4  Charlie-4  Biobank\n\n\nFor data from our specimen tracking system, I connect to it via an SQL connection. Then, by using the date I extracted from the filename, I filter out visits that happened after the most recent date the other data sources have data for (Note: To maintain privacy, I have ommitted and/or edited the connection string and query):\n\n### Sample Tracking System ###\n# Create a connection to SQL Server\n# cnxn = pyodbc.connect(YOUR CONNECTION STRING)\n\n# Make a query that gets all of the samples from visits for the study where the collection date is before the date on the sheets\n# query=\"SELECT Participant,visitnum FROM TABLENAME WHERE studynum=YOUR STUDY AND CollectionDate &lt;= '{}-{}-{}'\".format(dateparts[2],dateparts[0],dateparts[1])\n\n# Make a dataframe using the query and connection\n# lv=pd.read_sql(query,cnxn)\n\n# Close the connection\n# cnxn.close()\n\n# Read the Excel sheet\nlv=pd.read_excel(\"STS.xlsx\")\n\n# Convert visitnum's dtype into str\nlv[\"visitnum\"]=lv[\"visitnum\"].astype(str)\n\n# Create a column that combines the participant ID with the visit number\nlv[\"PartVis\"]=lv[\"Participant\"]+\"-\"+lv[\"visitnum\"]\n\nprint(lv)\n\n  Participant visitnum    PartVis\n0       Alpha        1    Alpha-1\n1       Bravo        1    Bravo-1\n2       Bravo        2    Bravo-2\n3     Charlie        5  Charlie-5\n\n\nTo start checking, I start by creating a list of unique participants in each data source. Then, I combine all of them into one list and remove duplicates by using the .set() method:\n\n### CROSS CHECK ###\n# Make a list of all of the unique participant-visit values for each source\nvepvList=list(vepv[\"PartVis\"].unique())\nbbpvList=list(bbpv[\"PartVis\"].unique())\nlvList=list(lv[\"PartVis\"].unique())\n\n# Combine all of the lists of unique participant-visit values for each source\nallPV=vepvList+bbpvList+lvList\n\n# Remove redundant values from the list\nallPV=list(set(allPV))\n\nprint(allPV)\n\n['Charlie-4', 'Alpha-1', 'Charlie-3', 'Alpha-2', 'Bravo-2', 'Bravo-1', 'Charlie-5']\n\n\nThe results will be outputted as a spreadsheet. To start, I will create an empty dataframe:\n\n# Create a dataframe that we will use to output a spreadsheet later. This sheet will contain the participant-visit values that was not found in one or two of the data sources\nmssgDF=pd.DataFrame(columns=['MSSG','Missing in','Participant','Visit'])\n\nprint(mssgDF)\n\nEmpty DataFrame\nColumns: [MSSG, Missing in, Participant, Visit]\nIndex: []\n\n\nTo compare the data sources, I loop through the list of unique participant-visit combos found in all data sources. Then, for each element, I check to make sure if it is in each data source. If it is not in a data source, I append a row to the output dataframe that has a message describing which participant-visit combo is missing from which data source, data source, participant, and visit:\n\nfor i in allPV: # For each value in the list of unique participant-visit values\n    if i not in vepvList: # If its not in the enrollment-visit sheet...\n        # Create a string that has a message saying that the particular participant-visit value was not found in the data source\n        mssg=\"Participant-Visit {} was not found in the Visit Enrollment sheet.\".format(str(i)) \n        # Split the participant-visit value into their components\n        j=i.split('-')\n        # Append it to the output dataframe\n        mssgDF.loc[len(mssgDF)]=[mssg,\"Visit Enrollment\",j[0],j[1]]\n    if i not in bbpvList: # If its not in the biobank sheet...\n        # Create a string that has a message saying that the particular participant-visit value was not found in the data source\n        mssg=\"Participant-Visit {} was not found in the BioBank sheet.\".format(str(i))\n        # Split the participant-visit value into their components\n        j=i.split('-')\n        # Append it to the output dataframe\n        mssgDF.loc[len(mssgDF)]=[mssg,\"BioBank\",j[0],j[1]]\n    if i not in lvList: # If its not in the LabVantage...\n        # Create a string that has a message saying that the particular participant-visit value was not found in the data source\n        mssg=\"Participant-Visit {} was not found in LV.\".format(str(i))\n        # Split the participant-visit value into their components\n        j=i.split('-')\n        # Append it to the output dataframe\n        mssgDF.loc[len(mssgDF)]=[mssg,\"LabVantage\",j[0],j[1]]\n\nprint(mssgDF)\n\n                                                MSSG        Missing in   \n0  Participant-Visit Charlie-4 was not found in t...  Visit Enrollment  \\\n1   Participant-Visit Charlie-4 was not found in LV.        LabVantage   \n2  Participant-Visit Charlie-3 was not found in t...           BioBank   \n3   Participant-Visit Charlie-3 was not found in LV.        LabVantage   \n4     Participant-Visit Alpha-2 was not found in LV.        LabVantage   \n5  Participant-Visit Bravo-2 was not found in the...  Visit Enrollment   \n6  Participant-Visit Bravo-1 was not found in the...           BioBank   \n7  Participant-Visit Charlie-5 was not found in t...  Visit Enrollment   \n8  Participant-Visit Charlie-5 was not found in t...           BioBank   \n\n  Participant Visit  \n0     Charlie     4  \n1     Charlie     4  \n2     Charlie     3  \n3     Charlie     3  \n4       Alpha     2  \n5       Bravo     2  \n6       Bravo     1  \n7     Charlie     5  \n8     Charlie     5  \n\n\nOutput the result as an Excel spreadsheet:\n\n# Output the dataframe as an xlsx file\nmssgDF.to_excel('resultDemo.xlsx',index=False)"
  },
  {
    "objectID": "python/correct-tube/data-cleaning.html",
    "href": "python/correct-tube/data-cleaning.html",
    "title": "Data Cleaning: Incorrect Tube Names",
    "section": "",
    "text": "This script automatically cleans the names of several tube names. The script takes in a spreadsheet as an input that has at least the following columns: * “Study Number” * “ISISS Registration Number” * “ITN Barcode” * “Tube Type”\nStart by importing libraries. I will import pandas to read and manage data extracted from Excel spreadsheets. Datetime will be used to generate the date this script is run to keep track of data change requests.\n\nimport pandas as pd\nfrom datetime import datetime\n\nI will start with getting today’s date. I need to get the date in a string format because data change requests need this information in the first column:\n\ntoday=datetime.now() # Gets today's date\nyear=str(today.year) # Get the year as a string\nyear=year[-2:]  # Get the last 2 digits (2023 -&gt; 23)\ndate=str(today.month)+'.'+str(today.day)+'.'+str(year) # Get today's date in MM-DD-YY format\n\nprint(date)\n\n7.19.23\n\n\nHave pandas read the spreadsheet:\n\nflag=pd.read_excel(\"dataDemo.xlsx\")\n\nprint(flag)\n\n   Study Number  ISISS Registration Number  ITN Barcode   \n0      ITNXXXYY                        101        10001  \\\n1      ITNXXXYY                        102        10002   \n2      ITNXXXYY                        103        10003   \n3      ITNXXXYY                        104        10004   \n4      ITNXXXYY                        105        10005   \n5      ITNXXXYY                        106        10006   \n6      ITNXXXYY                        107        10007   \n7      ITNXXXYY                        108        10008   \n8      ITNXXXYY                        109        10009   \n9      ITNXXXYY                        110        10010   \n10     ITNXXXYY                        111        10011   \n11     ITNXXXYY                        112        10012   \n12     ITNXXXYY                        113        10013   \n13     ITNXXXYY                        114        10014   \n14     ITNXXXYY                        115        10015   \n15     ITNXXXYY                        116        10016   \n16     ITNXXXYY                        117        10017   \n17     ITNXXXYY                        118        10018   \n18     ITNXXXYY                        119        10019   \n19     ITNXXXYY                        120        10020   \n20     ITNXXXYY                        121        10021   \n21     ITNXXXYY                        122        10022   \n22     ITNXXXYY                        123        10023   \n23     ITNXXXYY                        124        10024   \n24     ITNXXXYY                        125        10025   \n25     ITNXXXYY                        126        10026   \n26     ITNXXXYY                        127        10027   \n27     ITNXXXYY                        128        10028   \n28     ITNXXXYY                        129        10029   \n29     ITNXXXYY                        130        10030   \n30     ITNXXXYY                        131        10031   \n31     ITNXXXYY                        132        10032   \n32     ITNXXXYY                        133        10033   \n33     ITNXXXYY                        134        10034   \n34     ITNXXXYY                        135        10035   \n35     ITNXXXYY                        136        10036   \n36     ITNXXXYY                        137        10037   \n37     ITNXXXYY                        138        10038   \n38     ITNXXXYY                        139        10039   \n\n                  Tube Type  \n0          0.5  ML CRYOVIAL  \n1            0.5mL Cryovial  \n2           0.5 ML CRYOVIAL  \n3           1.2 mL Cryovial  \n4          01.2 ML CRYOVIAL  \n5            1.5ml cryovial  \n6          01.5 ML CRYOVIAL  \n7            1.8ml cryovial  \n8           01.8ml cryovial  \n9           1.8 mL cryovial  \n10                    1.8mL  \n11           1.8mL Cryovial  \n12      4'' 1.8 ml cryovial  \n13          1.8 mL cryovial  \n14         01.8 ML CRYOVIAL  \n15                  idk lol  \n16         02.0 ML CRYOVIAL  \n17          02.0mL Cryovial  \n18            02mL Cryovial  \n19             2ml cryovial  \n20             2mL Cryovial  \n21           02 ML CRYOVIAL  \n22          2.5 ml cryovial  \n23         02.5 ML CRYOVIAL  \n24              03mL Tempus  \n25              03mL Tempus  \n26             03 ML TEMPUS  \n27                 5ml EDTA  \n28            05 ML K3 EDTA  \n29      15 ml cryovial tube  \n30            15ML CRYOVIAL  \n31           15 ML CRYOVIAL  \n32            22 oz Commode  \n33  22 OZ COMMODE CONTAINER  \n34            35 ml Storage  \n35  35 ml Storage Container  \n36     35 ML STORAGE BOTTLE  \n37           RNA DNA Shield  \n38           DNA RNA Shield  \n\n\nGet a list of columns from the spreadsheet. Insert a new column called “New Tube Type” after the pre-existing “Tube Type” column:\n\ncolumn_list=list(flag.columns)\nflag.insert(loc=(column_list.index(\"Tube Type\")+1),column=\"New Tube Type\",value=None)\n\nCreate a function that maps incorrect tube names to correct ones. I am not using a dictionary since there are many incorrect tube names for one correct tube name. Furthermore, I believe that it is easier to edit the function. A new user would have an easier time understanding what the function does:\n\ndef cleaning(old):\n    if old in ['0.5  ML CRYOVIAL','0.5mL Cryovial']: # If the current tube name is one of these...\n        return '0.5 ML CRYOVIAL' # Return this name\n    elif (old == '1.2 mL Cryovial'): # Otherwise, if the current tube name is this...\n        return '01.2 ML CRYOVIAL' # Return this name\n    elif (old == '1.5ml cryovial'):\n        return '01.5 ML CRYOVIAL'\n    elif old in ['1.8ml cryovial','01.8ml cryovial','1.8 mL cryovial','1.8mL','1.8mL Cryovial',\"4'' 1.8 ml cryovial\",\"1.8 mL cryovial\"]:\n        return '01.8 ML CRYOVIAL'\n    elif old in ['02.0 ML CRYOVIAL','02.0mL Cryovial','02mL Cryovial','2ml cryovial',\"2mL Cryovial\"]:\n        return '02 ML CRYOVIAL'\n    elif old == '2.5 ml cryovial':\n        return '02.5 ML CRYOVIAL'\n    elif old in ['03mL Tempus',\"03mL Tempus\"]:\n        return '03 ML TEMPUS'\n    elif old == '5ml EDTA':\n        return '05 ML K3 EDTA'\n    elif old in ['15 ml cryovial tube',\"15ML CRYOVIAL\"]:\n        return '15 ML CRYOVIAL'\n    elif old == '22 oz Commode':\n        return '22 OZ COMMODE CONTAINER'\n    elif old in ['35 ml Storage','35 ml Storage Container']:\n        return '35 ML STORAGE BOTTLE'\n    elif old == 'RNA DNA Shield':\n        return 'DNA RNA Shield'\n    else:\n        return None\n\nApply the function:\n\nflag[\"New Tube Type\"]=flag[\"Tube Type\"].apply(cleaning)\n\nprint(flag)\n\n   Study Number  ISISS Registration Number  ITN Barcode   \n0      ITNXXXYY                        101        10001  \\\n1      ITNXXXYY                        102        10002   \n2      ITNXXXYY                        103        10003   \n3      ITNXXXYY                        104        10004   \n4      ITNXXXYY                        105        10005   \n5      ITNXXXYY                        106        10006   \n6      ITNXXXYY                        107        10007   \n7      ITNXXXYY                        108        10008   \n8      ITNXXXYY                        109        10009   \n9      ITNXXXYY                        110        10010   \n10     ITNXXXYY                        111        10011   \n11     ITNXXXYY                        112        10012   \n12     ITNXXXYY                        113        10013   \n13     ITNXXXYY                        114        10014   \n14     ITNXXXYY                        115        10015   \n15     ITNXXXYY                        116        10016   \n16     ITNXXXYY                        117        10017   \n17     ITNXXXYY                        118        10018   \n18     ITNXXXYY                        119        10019   \n19     ITNXXXYY                        120        10020   \n20     ITNXXXYY                        121        10021   \n21     ITNXXXYY                        122        10022   \n22     ITNXXXYY                        123        10023   \n23     ITNXXXYY                        124        10024   \n24     ITNXXXYY                        125        10025   \n25     ITNXXXYY                        126        10026   \n26     ITNXXXYY                        127        10027   \n27     ITNXXXYY                        128        10028   \n28     ITNXXXYY                        129        10029   \n29     ITNXXXYY                        130        10030   \n30     ITNXXXYY                        131        10031   \n31     ITNXXXYY                        132        10032   \n32     ITNXXXYY                        133        10033   \n33     ITNXXXYY                        134        10034   \n34     ITNXXXYY                        135        10035   \n35     ITNXXXYY                        136        10036   \n36     ITNXXXYY                        137        10037   \n37     ITNXXXYY                        138        10038   \n38     ITNXXXYY                        139        10039   \n\n                  Tube Type            New Tube Type  \n0          0.5  ML CRYOVIAL                     None  \n1            0.5mL Cryovial          0.5 ML CRYOVIAL  \n2           0.5 ML CRYOVIAL                     None  \n3           1.2 mL Cryovial         01.2 ML CRYOVIAL  \n4          01.2 ML CRYOVIAL                     None  \n5            1.5ml cryovial         01.5 ML CRYOVIAL  \n6          01.5 ML CRYOVIAL                     None  \n7            1.8ml cryovial         01.8 ML CRYOVIAL  \n8           01.8ml cryovial         01.8 ML CRYOVIAL  \n9           1.8 mL cryovial         01.8 ML CRYOVIAL  \n10                    1.8mL         01.8 ML CRYOVIAL  \n11           1.8mL Cryovial         01.8 ML CRYOVIAL  \n12      4'' 1.8 ml cryovial         01.8 ML CRYOVIAL  \n13          1.8 mL cryovial         01.8 ML CRYOVIAL  \n14         01.8 ML CRYOVIAL                     None  \n15                  idk lol                     None  \n16         02.0 ML CRYOVIAL           02 ML CRYOVIAL  \n17          02.0mL Cryovial           02 ML CRYOVIAL  \n18            02mL Cryovial           02 ML CRYOVIAL  \n19             2ml cryovial           02 ML CRYOVIAL  \n20             2mL Cryovial           02 ML CRYOVIAL  \n21           02 ML CRYOVIAL                     None  \n22          2.5 ml cryovial         02.5 ML CRYOVIAL  \n23         02.5 ML CRYOVIAL                     None  \n24              03mL Tempus             03 ML TEMPUS  \n25              03mL Tempus             03 ML TEMPUS  \n26             03 ML TEMPUS                     None  \n27                 5ml EDTA            05 ML K3 EDTA  \n28            05 ML K3 EDTA                     None  \n29      15 ml cryovial tube           15 ML CRYOVIAL  \n30            15ML CRYOVIAL           15 ML CRYOVIAL  \n31           15 ML CRYOVIAL                     None  \n32            22 oz Commode  22 OZ COMMODE CONTAINER  \n33  22 OZ COMMODE CONTAINER                     None  \n34            35 ml Storage     35 ML STORAGE BOTTLE  \n35  35 ml Storage Container     35 ML STORAGE BOTTLE  \n36     35 ML STORAGE BOTTLE                     None  \n37           RNA DNA Shield           DNA RNA Shield  \n38           DNA RNA Shield                     None  \n\n\nI still need to clean the spreadsheet. A data change request is submitted when there is new information. Therefore, NaNs have to be removed since they cannot be used for data change requests:\n\nflag=flag[flag[\"New Tube Type\"].notna()]\n\nA Data Change Request Number is needed to submit a data change request. The value is the same for all columns. It is a string in the format {Study number} - MM-DD-YY - Initials. The code below accomplishes this task:\n\nflag[\"Data Change Request Number\"]=flag[\"Study Number\"]+\" - \"+date+\" - LS\"\n\nA “change number” is needed for each row. This just shows the first, second, third, … , and nth data change to be made. An easy way to do this is to reset the index, then create a column that is the index + 1:\n\nflag.reset_index(inplace=True)\nflag[\"Index\"]=flag.index\nflag[\"Change Number\"]=flag[\"Index\"]+1\n\nTo submit the data change request, only the following columns from the dataframe are needed: - Data Change Request Number - Change Number - ISISS Registration Number - ITN Barcode - Tube Type - New Tube Type\nThus, I will only select these columns from the dataframe. Lastly, a justification column is needed. I will assign a string value to a “Justification” column.\n\n# Select columns\nflag=flag[[\"Data Change Request Number\",\"Change Number\",\"ISISS Registration Number\",\"ITN Barcode\",\"Tube Type\",\"New Tube Type\"]]\n\n# Create the justification column\nflag[\"Justification\"]='''reconciling data entry inconsistencies'''\n\nExport the dataframe as an Excel spreadsheet. This will be emailed to a group that handles data changes:\n\nflag.to_excel(\"Data Change Request Demo.xlsx\",index=False)"
  },
  {
    "objectID": "python/date-a-scientist/date-a-scientist.html",
    "href": "python/date-a-scientist/date-a-scientist.html",
    "title": "Date-A-Scientist Portfolio Project",
    "section": "",
    "text": "This project was done through CodeAcademy’s Data Scientist career path."
  },
  {
    "objectID": "python/date-a-scientist/date-a-scientist.html#examine-data",
    "href": "python/date-a-scientist/date-a-scientist.html#examine-data",
    "title": "Date-A-Scientist Portfolio Project",
    "section": "Examine Data",
    "text": "Examine Data\nBefore anything else, I will examine the data so that we can get a good understanding of the data available to us.\n\n#Import necessary modules\nimport pandas as pd\nimport numpy as np\n\n#Load dataframe\ndf=pd.read_csv('profiles.csv')\n\n#Get first few rows, column names, data types\nprint(df.dtypes)\ndf.head()\n\nage              int64\nbody_type       object\ndiet            object\ndrinks          object\ndrugs           object\neducation       object\nessay0          object\nessay1          object\nessay2          object\nessay3          object\nessay4          object\nessay5          object\nessay6          object\nessay7          object\nessay8          object\nessay9          object\nethnicity       object\nheight         float64\nincome           int64\njob             object\nlast_online     object\nlocation        object\noffspring       object\norientation     object\npets            object\nreligion        object\nsex             object\nsign            object\nsmokes          object\nspeaks          object\nstatus          object\ndtype: object\n\n\n\n\n\n\n\n\n\nage\nbody_type\ndiet\ndrinks\ndrugs\neducation\nessay0\nessay1\nessay2\nessay3\n...\nlocation\noffspring\norientation\npets\nreligion\nsex\nsign\nsmokes\nspeaks\nstatus\n\n\n\n\n0\n22\na little extra\nstrictly anything\nsocially\nnever\nworking on college/university\nabout me:&lt;br /&gt;\\n&lt;br /&gt;\\ni would love to think...\ncurrently working as an international agent fo...\nmaking people laugh.&lt;br /&gt;\\nranting about a go...\nthe way i look. i am a six foot half asian, ha...\n...\nsouth san francisco, california\ndoesn&rsquo;t have kids, but might want them\nstraight\nlikes dogs and likes cats\nagnosticism and very serious about it\nm\ngemini\nsometimes\nenglish\nsingle\n\n\n1\n35\naverage\nmostly other\noften\nsometimes\nworking on space camp\ni am a chef: this is what that means.&lt;br /&gt;\\n1...\ndedicating everyday to being an unbelievable b...\nbeing silly. having ridiculous amonts of fun w...\nNaN\n...\noakland, california\ndoesn&rsquo;t have kids, but might want them\nstraight\nlikes dogs and likes cats\nagnosticism but not too serious about it\nm\ncancer\nno\nenglish (fluently), spanish (poorly), french (...\nsingle\n\n\n2\n38\nthin\nanything\nsocially\nNaN\ngraduated from masters program\ni'm not ashamed of much, but writing public te...\ni make nerdy software for musicians, artists, ...\nimprovising in different contexts. alternating...\nmy large jaw and large glasses are the physica...\n...\nsan francisco, california\nNaN\nstraight\nhas cats\nNaN\nm\npisces but it doesn&rsquo;t matter\nno\nenglish, french, c++\navailable\n\n\n3\n23\nthin\nvegetarian\nsocially\nNaN\nworking on college/university\ni work in a library and go to school. . .\nreading things written by old dead people\nplaying synthesizers and organizing books acco...\nsocially awkward but i do my best\n...\nberkeley, california\ndoesn&rsquo;t want kids\nstraight\nlikes cats\nNaN\nm\npisces\nno\nenglish, german (poorly)\nsingle\n\n\n4\n29\nathletic\nNaN\nsocially\nnever\ngraduated from college/university\nhey how's it going? currently vague on the pro...\nwork work work work + play\ncreating imagery to look at:&lt;br /&gt;\\nhttp://bag...\ni smile a lot and my inquisitive nature\n...\nsan francisco, california\nNaN\nstraight\nlikes dogs and likes cats\nNaN\nm\naquarius\nno\nenglish\nsingle\n\n\n\n\n5 rows × 31 columns\n\n\n\nThe goal: we can try to predict who is single based on their profile information. By being able to predict whether a user is single, OkCupid can market to such users in a different way (as opposed to people who are not single, as people already in relationships might use OkCupid or another site to make friends).\n\nAge may be a relevant category. Some statistics show differences in the rate of being single in different age groups.\nDrinks may be relevant, as alcohol is used as a social lubricant and may be a way people use to connect. This may increase the chances of someone finding someone they like. The same goes for drugs.\nHeight may be an indicator. There are varying preferences for height.\nIncome may be relevant as it gives the individual more freedom to do the things they want to do, which may increase the chances of them meeting someone they like because they can afford to do so.\nEducation may be relevant as being in education may limit the time someone has for dating. However, one could also argue that being in a social environment with people who are roughly the same age as you may increase the probability of one finding someone they like.\nJobs may be relevant to one’s relationship status. Some people may want to date someone who they can relate to better in this context. Alternatively, one might see the professional benefits of such a relationship.\nSex may be relevant. There are differing rates of being single based on sex.\n\nStatus is the target.\nOk, it looks like the following are features worth considering:\n’‘’age,drinks,drugs,height,income,education,job,sex,last online,status’’’\nBefore we begin, I will modify the data so that it will be easier to graph and model. One thing I need to do is to remove all NaN values.\n\nfeature_list=['age','drinks','drugs','height','income','education','job','sex','last_online','status']\nplotting_df=df[feature_list]\nplotting_df.dropna(how=\"any\",inplace=True)\n\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\2607736166.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.dropna(how=\"any\",inplace=True)\n\n\nNext, I will examine each column to find data that might cause issues. Lets start with age.\n\nprint(plotting_df.age.value_counts())\n\nage\n27    2272\n26    2269\n28    2135\n25    2077\n24    1975\n29    1952\n30    1893\n31    1613\n23    1568\n32    1558\n33    1336\n22    1149\n34    1120\n35    1030\n36     935\n37     864\n38     796\n21     787\n39     713\n42     657\n40     631\n41     616\n20     606\n43     535\n44     452\n45     424\n46     366\n19     349\n48     343\n47     343\n49     320\n50     301\n52     256\n51     229\n56     193\n54     190\n55     186\n57     185\n18     176\n59     163\n53     163\n58     146\n61     142\n60     139\n62     127\n63     107\n65      84\n66      82\n64      78\n67      53\n68      46\n69      21\nName: count, dtype: int64\n\n\nNo issue here, lets move on to drinks.\n\nprint(plotting_df.drinks.value_counts())\n\ndrinks\nsocially       26279\nrarely          4351\noften           3143\nnot at all      2473\nvery often       319\ndesperately      186\nName: count, dtype: int64\n\n\nNo problems here. Lets move on to drugs.\n\nprint(plotting_df.drugs.value_counts())\n\ndrugs\nnever        30090\nsometimes     6335\noften          326\nName: count, dtype: int64\n\n\nGreat! Lets move onto height and income:\n\nprint(plotting_df.height.value_counts())\nprint(plotting_df.income.value_counts())\n\nheight\n70.0    3674\n68.0    3359\n67.0    3351\n72.0    3171\n69.0    3155\n66.0    3006\n71.0    2890\n65.0    2403\n64.0    2379\n73.0    1750\n63.0    1720\n74.0    1506\n62.0    1410\n75.0     832\n61.0     647\n76.0     475\n60.0     469\n77.0     167\n59.0     134\n78.0      74\n58.0      37\n79.0      36\n80.0      17\n82.0      10\n95.0      10\n81.0       9\n83.0       8\n57.0       8\n56.0       6\n55.0       4\n53.0       4\n54.0       3\n94.0       3\n36.0       3\n43.0       2\n84.0       2\n91.0       2\n88.0       1\n85.0       1\n26.0       1\n1.0        1\n37.0       1\n51.0       1\n9.0        1\n48.0       1\n90.0       1\n49.0       1\n47.0       1\n87.0       1\n86.0       1\n3.0        1\n4.0        1\nName: count, dtype: int64\nincome\n-1          27898\n 20000       2381\n 100000      1217\n 80000        851\n 30000        809\n 40000        779\n 50000        743\n 60000        563\n 70000        549\n 150000       475\n 1000000      353\n 250000       103\n 500000        30\nName: count, dtype: int64\n\n\nThe income value of -1 may cause issues with normalization later on. I will change them to zeros.\n\nplotting_df.loc[(plotting_df.income == -1),'income']=0\nprint(plotting_df.income.value_counts())\n\nincome\n0          27898\n20000       2381\n100000      1217\n80000        851\n30000        809\n40000        779\n50000        743\n60000        563\n70000        549\n150000       475\n1000000      353\n250000       103\n500000        30\nName: count, dtype: int64\n\n\nAwesome! Lets check out education:\n\nprint(plotting_df.education.value_counts())\n\neducation\ngraduated from college/university    15852\ngraduated from masters program        6332\nworking on college/university         4147\ngraduated from two-year college       1227\ngraduated from high school            1126\nworking on masters program            1095\ngraduated from ph.d program            951\nworking on two-year college            828\ngraduated from law school              735\ndropped out of college/university      727\nworking on ph.d program                648\ncollege/university                     479\ngraduated from space camp              453\ngraduated from med school              350\ndropped out of space camp              330\nworking on space camp                  272\nworking on law school                  164\ntwo-year college                       159\nworking on med school                  153\ndropped out of two-year college        146\ndropped out of masters program          96\ndropped out of ph.d program             91\ndropped out of high school              85\nmasters program                         78\nworking on high school                  71\nhigh school                             69\nspace camp                              29\nph.d program                            19\ndropped out of law school               13\ndropped out of med school               10\nlaw school                              10\nmed school                               6\nName: count, dtype: int64\n\n\nOne problem here is that some entries are not specific. For example, six people stated for their education “med school”. However, this does not tell me whether they are enrolled in med school. I will count how many entries in the education column are not specific.\n\nspec_count=0\nunspec_count=0\nfor edu in plotting_df.loc[:,'education']:\n    if 'graduated' in edu or 'working on' in edu or 'dropped out' in edu:\n        spec_count+=1\n    else:\n        unspec_count+=1\nprint(unspec_count)\nprint(unspec_count/(spec_count+unspec_count))\n\n849\n0.02310141220647057\n\n\n498 profiles have non-specific entries for the ‘education’ part of the profile. Removing these entries will only remove 2% of the current dataset. I will remove this data since it is a small fraction of the total dataset.\n\nplotting_df.drop(plotting_df[(plotting_df.loc[:,'education']==\"college/university\")|\n                            (plotting_df['education']==\"two-year college\")|\n                             (plotting_df['education']==\"high school\")|\n                             (plotting_df['education']==\"masters program\")|\n                             (plotting_df['education']==\"space camp\")|\n                             (plotting_df['education']==\"ph.d program\")|\n                             (plotting_df['education']==\"law school\")|\n                             (plotting_df['education']==\"med school\")\n                            ].index,inplace=True)\nprint(plotting_df['education'].value_counts())\nspec_count=0\nunspec_count=0\nfor edu in plotting_df['education']:\n    if 'graduated' in edu or 'working on' in edu or 'dropped out' in edu:\n        spec_count+=1\n    else:\n        unspec_count+=1\nprint(unspec_count)\nprint(unspec_count/(spec_count+unspec_count))\n\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\1761148565.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.drop(plotting_df[(plotting_df.loc[:,'education']==\"college/university\")|\n\n\neducation\ngraduated from college/university    15852\ngraduated from masters program        6332\nworking on college/university         4147\ngraduated from two-year college       1227\ngraduated from high school            1126\nworking on masters program            1095\ngraduated from ph.d program            951\nworking on two-year college            828\ngraduated from law school              735\ndropped out of college/university      727\nworking on ph.d program                648\ngraduated from space camp              453\ngraduated from med school              350\ndropped out of space camp              330\nworking on space camp                  272\nworking on law school                  164\nworking on med school                  153\ndropped out of two-year college        146\ndropped out of masters program          96\ndropped out of ph.d program             91\ndropped out of high school              85\nworking on high school                  71\ndropped out of law school               13\ndropped out of med school               10\nName: count, dtype: int64\n0\n0.0\n\n\nMy rationale for the education column is that being in school (i.e. enrolled) itself is enough of a differentiator because any form of schooling is a significant time commitment (assuming that the students themselves are committed). I will edit these values so that 0 is not enrolled and 1 is enrolled.\n\nplotting_df.loc[:,'in_edu']=plotting_df.loc[:,'education'].apply(lambda x: 0 if \"graduated\" in x or \"dropped out\" in x else 1)\n\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\463722713.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.loc[:,'in_edu']=plotting_df.loc[:,'education'].apply(lambda x: 0 if \"graduated\" in x or \"dropped out\" in x else 1)\n\n\nCool! Now I will inspect jobs.\n\nprint(plotting_df.job.value_counts())\n\njob\nother                                5123\nstudent                              3683\nscience / tech / engineering         3419\ncomputer / hardware / software       3243\nsales / marketing / biz dev          3042\nartistic / musical / writer          2924\nmedicine / health                    2614\neducation / academia                 2503\nexecutive / management               1670\nbanking / financial / real estate    1621\nentertainment / media                1426\nlaw / legal services                  912\nhospitality / travel                  890\nconstruction / craftsmanship          630\nclerical / administrative             557\npolitical / government                521\nrather not say                        308\ntransportation                        248\nunemployed                            221\nretired                               183\nmilitary                              164\nName: count, dtype: int64\n\n\nLastly, I will examine sex and status.\n\nprint(plotting_df['sex'].value_counts())\nprint(plotting_df['status'].value_counts())\n\nsex\nm    21306\nf    14596\nName: count, dtype: int64\nstatus\nsingle            33332\nseeing someone     1266\navailable          1093\nmarried             207\nunknown               4\nName: count, dtype: int64\n\n\nThe unknown relationship status may not give us a lot of insight. They also represent a small fraction of our total dataset. I will remove them.\n\nplotting_df.loc[:,'status'].drop(plotting_df[plotting_df.loc[:,'status']=='unknown'].index,inplace=True)\n\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\701518949.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.loc[:,'status'].drop(plotting_df[plotting_df.loc[:,'status']=='unknown'].index,inplace=True)\n\n\nNow, I will examine the last_online column.\n\nprint(plotting_df['last_online'].value_counts)\n\n&lt;bound method IndexOpsMixin.value_counts of 0        2012-06-28-20-30\n1        2012-06-29-21-41\n4        2012-06-27-21-26\n7        2012-06-29-12-30\n9        2012-06-28-21-08\n               ...       \n59939    2012-07-01-06-08\n59941    2012-06-12-21-47\n59942    2012-06-29-11-01\n59943    2012-06-27-23-37\n59944    2012-06-23-13-01\nName: last_online, Length: 35902, dtype: object&gt;\n\n\nI will alter this data so that we get the days since we last saw the person on the website. I think that this will help with getting data that is more useful for ML models because it is a statistic that shows a user’s interest in the app’s services.\n\nfrom datetime import date\nplotting_df.loc[:,'last_online'] = pd.to_datetime(plotting_df.loc[:,'last_online'], format='%Y-%m-%d-%H-%M')\nplotting_df.loc[:,\"last_online\"]=plotting_df.loc[:,\"last_online\"].astype('datetime64[ns]')\nplotting_df.loc[:,\"most recent\"]=plotting_df.loc[:,\"last_online\"].sort_values(ascending=False).iloc[0]\nprint(plotting_df.loc[:,\"last_online\"].sort_values(ascending=False))\nplotting_df.loc[:,\"days since last seen\"]=plotting_df.loc[:,\"most recent\"].astype('datetime64[ns]')-plotting_df.loc[:,\"last_online\"].astype('datetime64[ns]')\nprint(plotting_df.loc[:,\"days since last seen\"].dtype)\nplotting_df.loc[:,\"days since last seen\"]=plotting_df.loc[:,\"days since last seen\"].apply(lambda x:x.days)\nprint(plotting_df.loc[:,\"days since last seen\"].sort_values(ascending=False))\n\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\3662312634.py:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.loc[:,\"most recent\"]=plotting_df.loc[:,\"last_online\"].sort_values(ascending=False).iloc[0]\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\3662312634.py:6: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.loc[:,\"days since last seen\"]=plotting_df.loc[:,\"most recent\"].astype('datetime64[ns]')-plotting_df.loc[:,\"last_online\"].astype('datetime64[ns]')\n\n\n59873   2012-07-01 08:57:00\n59838   2012-07-01 08:56:00\n59826   2012-07-01 08:56:00\n59819   2012-07-01 08:56:00\n59842   2012-07-01 08:56:00\n                ...        \n43845   2011-06-27 10:48:00\n40423   2011-06-27 10:36:00\n58982   2011-06-27 09:33:00\n13384   2011-06-27 08:25:00\n30466   2011-06-27 01:52:00\nName: last_online, Length: 35902, dtype: datetime64[ns]\ntimedelta64[ns]\n30466    370\n13384    370\n1162     369\n10864    369\n37418    369\n        ... \n19403      0\n30650      0\n45571      0\n19409      0\n47617      0\nName: days since last seen, Length: 35902, dtype: int64\n\n\nI will plot some scatter plots to see if there is any correlation between these features. I will update the features list.\n\nfeature_list=['age','drinks','drugs','height','income','in_edu','job','sex','days since last seen','status']\nfeature_list1=['age','drinks','drugs','height','income','in_edu','job','days since last seen','sex']\n\n\nfrom matplotlib import pyplot as plt\nfor feature in feature_list:\n    plt.scatter(plotting_df[feature],plotting_df.status,alpha=.1)\n    plt.title(feature)\n    plt.xticks(rotation=30)\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSome of these graphs show some correlation. For example, there are single people all across the age x-axis, but more 20-40 year olds are married. There aren’t as many people who desperately need to drink who are married (perhaps alcohol consumption can abate relationships). It looks like not a lot of people who do drugs often are married. Since these are categorical labels, I will make individual columns for each choice. Based on the above, I believe that it would be best to use a KNN classifier (in a future use case, it may also be useful to see what determines other relationship statuses). Before I begin, I will need to normalize the data.\n\nplotting_df.loc[:,\"is single\"]=np.where(plotting_df.loc[:,\"status\"]=='single',1,0)\ncolumns_to_change=[\"drinks\",\"drugs\",\"job\",\"sex\"]\nfor column in columns_to_change:\n    value_list=pd.unique(plotting_df.loc[:,column])\n    for value in value_list:\n        new_col_name=column+' '+value+'?'\n        plotting_df.loc[:,new_col_name]=np.where(plotting_df.loc[:,column]==value,1,0)\nplotting_df.drop(columns=[\"drinks\",\"drugs\",\"job\",\"sex\",\"education\",\"last_online\",\"status\",\"most recent\"],inplace=True)\nprint(plotting_df.columns)\nprint(plotting_df.head())\n\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\3404684793.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.loc[:,\"is single\"]=np.where(plotting_df.loc[:,\"status\"]=='single',1,0)\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\3404684793.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.loc[:,new_col_name]=np.where(plotting_df.loc[:,column]==value,1,0)\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\3404684793.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.loc[:,new_col_name]=np.where(plotting_df.loc[:,column]==value,1,0)\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\3404684793.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.loc[:,new_col_name]=np.where(plotting_df.loc[:,column]==value,1,0)\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\3404684793.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.loc[:,new_col_name]=np.where(plotting_df.loc[:,column]==value,1,0)\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\3404684793.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.loc[:,new_col_name]=np.where(plotting_df.loc[:,column]==value,1,0)\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\3404684793.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.loc[:,new_col_name]=np.where(plotting_df.loc[:,column]==value,1,0)\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\3404684793.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.loc[:,new_col_name]=np.where(plotting_df.loc[:,column]==value,1,0)\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\3404684793.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.loc[:,new_col_name]=np.where(plotting_df.loc[:,column]==value,1,0)\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\3404684793.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.loc[:,new_col_name]=np.where(plotting_df.loc[:,column]==value,1,0)\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\3404684793.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.loc[:,new_col_name]=np.where(plotting_df.loc[:,column]==value,1,0)\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\3404684793.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.loc[:,new_col_name]=np.where(plotting_df.loc[:,column]==value,1,0)\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\3404684793.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.loc[:,new_col_name]=np.where(plotting_df.loc[:,column]==value,1,0)\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\3404684793.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.loc[:,new_col_name]=np.where(plotting_df.loc[:,column]==value,1,0)\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\3404684793.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.loc[:,new_col_name]=np.where(plotting_df.loc[:,column]==value,1,0)\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\3404684793.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.loc[:,new_col_name]=np.where(plotting_df.loc[:,column]==value,1,0)\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\3404684793.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.loc[:,new_col_name]=np.where(plotting_df.loc[:,column]==value,1,0)\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\3404684793.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.loc[:,new_col_name]=np.where(plotting_df.loc[:,column]==value,1,0)\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\3404684793.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.loc[:,new_col_name]=np.where(plotting_df.loc[:,column]==value,1,0)\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\3404684793.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.loc[:,new_col_name]=np.where(plotting_df.loc[:,column]==value,1,0)\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\3404684793.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.loc[:,new_col_name]=np.where(plotting_df.loc[:,column]==value,1,0)\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\3404684793.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.loc[:,new_col_name]=np.where(plotting_df.loc[:,column]==value,1,0)\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\3404684793.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.loc[:,new_col_name]=np.where(plotting_df.loc[:,column]==value,1,0)\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\3404684793.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.loc[:,new_col_name]=np.where(plotting_df.loc[:,column]==value,1,0)\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\3404684793.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.loc[:,new_col_name]=np.where(plotting_df.loc[:,column]==value,1,0)\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\3404684793.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.loc[:,new_col_name]=np.where(plotting_df.loc[:,column]==value,1,0)\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\3404684793.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.loc[:,new_col_name]=np.where(plotting_df.loc[:,column]==value,1,0)\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\3404684793.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.loc[:,new_col_name]=np.where(plotting_df.loc[:,column]==value,1,0)\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\3404684793.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.loc[:,new_col_name]=np.where(plotting_df.loc[:,column]==value,1,0)\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\3404684793.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.loc[:,new_col_name]=np.where(plotting_df.loc[:,column]==value,1,0)\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\3404684793.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.loc[:,new_col_name]=np.where(plotting_df.loc[:,column]==value,1,0)\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\3404684793.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.loc[:,new_col_name]=np.where(plotting_df.loc[:,column]==value,1,0)\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\3404684793.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.loc[:,new_col_name]=np.where(plotting_df.loc[:,column]==value,1,0)\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29652\\3404684793.py:8: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  plotting_df.drop(columns=[\"drinks\",\"drugs\",\"job\",\"sex\",\"education\",\"last_online\",\"status\",\"most recent\"],inplace=True)\n\n\nIndex(['age', 'height', 'income', 'in_edu', 'days since last seen',\n       'is single', 'drinks socially?', 'drinks often?', 'drinks not at all?',\n       'drinks rarely?', 'drinks very often?', 'drinks desperately?',\n       'drugs never?', 'drugs sometimes?', 'drugs often?',\n       'job transportation?', 'job hospitality / travel?',\n       'job artistic / musical / writer?', 'job student?',\n       'job banking / financial / real estate?',\n       'job sales / marketing / biz dev?', 'job other?',\n       'job medicine / health?', 'job science / tech / engineering?',\n       'job executive / management?', 'job education / academia?',\n       'job clerical / administrative?', 'job computer / hardware / software?',\n       'job entertainment / media?', 'job rather not say?',\n       'job political / government?', 'job law / legal services?',\n       'job construction / craftsmanship?', 'job unemployed?', 'job military?',\n       'job retired?', 'sex m?', 'sex f?'],\n      dtype='object')\n   age  height  income  in_edu  days since last seen  is single   \n0   22    75.0       0       1                     2          1  \\\n1   35    70.0   80000       1                     1          1   \n4   29    66.0       0       0                     3          1   \n7   31    65.0       0       0                     1          1   \n9   37    65.0       0       1                     2          1   \n\n   drinks socially?  drinks often?  drinks not at all?  drinks rarely?  ...   \n0                 1              0                   0               0  ...  \\\n1                 0              1                   0               0  ...   \n4                 1              0                   0               0  ...   \n7                 1              0                   0               0  ...   \n9                 0              0                   1               0  ...   \n\n   job entertainment / media?  job rather not say?   \n0                           0                    0  \\\n1                           0                    0   \n4                           0                    0   \n7                           0                    0   \n9                           0                    0   \n\n   job political / government?  job law / legal services?   \n0                            0                          0  \\\n1                            0                          0   \n4                            0                          0   \n7                            0                          0   \n9                            0                          0   \n\n   job construction / craftsmanship?  job unemployed?  job military?   \n0                                  0                0              0  \\\n1                                  0                0              0   \n4                                  0                0              0   \n7                                  0                0              0   \n9                                  0                0              0   \n\n   job retired?  sex m?  sex f?  \n0             0       1       0  \n1             0       1       0  \n4             0       1       0  \n7             0       0       1  \n9             0       1       0  \n\n[5 rows x 38 columns]\n\n\n\nfrom sklearn.preprocessing import scale\ndf1=plotting_df\nfeature_list1=['age', 'height', 'income', 'in_edu', 'days since last seen',\n        'drinks socially?', 'drinks often?', 'drinks not at all?',\n       'drinks rarely?', 'drinks very often?', 'drinks desperately?',\n       'drugs never?', 'drugs sometimes?', 'drugs often?',\n       'job transportation?', 'job hospitality / travel?',\n       'job artistic / musical / writer?', 'job student?',\n       'job banking / financial / real estate?',\n       'job sales / marketing / biz dev?', 'job other?',\n       'job medicine / health?', 'job science / tech / engineering?',\n       'job executive / management?', 'job education / academia?',\n       'job clerical / administrative?', 'job computer / hardware / software?',\n       'job entertainment / media?', 'job rather not say?',\n       'job political / government?', 'job law / legal services?',\n       'job construction / craftsmanship?', 'job unemployed?', 'job military?',\n       'job retired?', 'sex m?', 'sex f?']\ndata=df1[feature_list1]\nlabel=df1[\"is single\"]\nscaled_data=scale(data,axis=0)\n\nHere, I will build and train the model.\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nscores=[]\nfor k in list(range(1,20)):\n    classifier=KNeighborsClassifier(n_neighbors=k)\n    train_data,test_data,train_label,test_label=train_test_split(scaled_data,label,train_size=.8,test_size=.2,random_state=1)\n    classifier.fit(train_data,train_label)\n    print(str(k)+\" || \"+str(classifier.score(test_data,test_label)))\n    scores.append(classifier.score(test_data,test_label))\nplt.close(\"all\")\nplt.plot(list(range(1,20)),scores)\nplt.show()\n\n1 || 0.8774543935385044\n2 || 0.8321960729703384\n3 || 0.9157498955577218\n4 || 0.9027990530566773\n5 || 0.9254978415262498\n6 || 0.9224342013647124\n7 || 0.9284222253168083\n8 || 0.9268904052360395\n9 || 0.92953627628464\n10 || 0.9285614816877872\n11 || 0.9302325581395349\n12 || 0.9300933017685559\n13 || 0.9302325581395349\n14 || 0.9302325581395349\n15 || 0.9305110708814929\n16 || 0.9302325581395349\n17 || 0.9305110708814929\n18 || 0.9303718145105139\n19 || 0.9306503272524718\n\n\n\n\n\nIt looks like the efficacy of the model starts to taper at around k=11 to k=19. k=15 seems reasonable. Our R-squared is .93."
  },
  {
    "objectID": "python/date-a-scientist/date-a-scientist.html#conclusion",
    "href": "python/date-a-scientist/date-a-scientist.html#conclusion",
    "title": "Date-A-Scientist Portfolio Project",
    "section": "Conclusion:",
    "text": "Conclusion:\nWhat I learned: 1. We can predict whether someone is single with an accuracy of around .93. 2. Learned the recommended ways of calling columns and the data inside them.\nThis model can be augmented to predict other categorical features of OkCupid users. This model may be able to be improved by utilizing the data from user essays. NLP would be a good tool for this."
  },
  {
    "objectID": "python.html",
    "href": "python.html",
    "title": "Python Projects",
    "section": "",
    "text": "Here are my Python projects:\nChecking Samples Between Three Data Sources\nCorrecting Tube Names\nDate-a-scientist"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Bachelor of Arts, Double Major in Mathematics and Philosophy, GPA: 3.5\nRelevant Coursework: Linear and Nonlinear Optimization; Modeling and Simulation in Science, Engineering, and Economics; Probability and Statistics"
  },
  {
    "objectID": "resume.html#education",
    "href": "resume.html#education",
    "title": "Resume",
    "section": "",
    "text": "Bachelor of Arts, Double Major in Mathematics and Philosophy, GPA: 3.5\nRelevant Coursework: Linear and Nonlinear Optimization; Modeling and Simulation in Science, Engineering, and Economics; Probability and Statistics"
  },
  {
    "objectID": "resume.html#technical-skills",
    "href": "resume.html#technical-skills",
    "title": "Resume",
    "section": "Technical Skills",
    "text": "Technical Skills\n\nCoding Languages/Libraries:\n\nPython, MATLAB, SQL, Scikit-Learn, Pandas, Seaborn, Matplotlib, Selenium\n\nSoftware:\n\nMS Office, Microsoft Excel, Tableau, Jira\n\nLanguages:\n\nIntermediate Japanese\n\nOther Tools:\n\nJupyter Notebook"
  },
  {
    "objectID": "resume.html#projects",
    "href": "resume.html#projects",
    "title": "Resume",
    "section": "Projects",
    "text": "Projects\n\nConvoy/Parade Traffic Simulation (MATLAB, GitHub Version Control) | Dec 2021\n\nCoded a traffic simulation by conceptualizing a two-dimensional route as a one-dimensional line.\nSimulated and recorded 6 possible scenarios a convoy or parade could encounter.\nPresented the project to a 20-person class with an explanation of the model, code, and simulations of scenarios.\n\n\n\nDating App Profile Analysis Project (Python, Jupyter Notebook) | Aug 2021\n\nImplemented data analysis and science skills learned through Codecademy’s Data Science Career Path.\nIncorporated the Pandas library to clean &gt;60,000 data points and Scikit-Learn to build and train a machine learning algorithm.\nModel reached 93% accuracy in determining a user’s relationship status based on user profile information."
  },
  {
    "objectID": "resume.html#experience",
    "href": "resume.html#experience",
    "title": "Resume",
    "section": "Experience",
    "text": "Experience\n\nResearch Data Analyst, Immune Tolerance Network at UCSF, San Francisco, CA | Feb 2023 - Present\n\nWrote &gt;5 data cleaning scripts using Python’s Pandas library, generating datasets from sample management database systems.\nOne script automatically fixed ~1,500 records, correcting ~75% of tube name errors, including those in transplant studies.\nWrote a webscraper to collect shipping data from a courier that did not have a dedicated tracking information API.\n\n\n\nLab Research Assistant, The Nusse Lab at Stanford University School of Medicine, Stanford, CA | Jun 2018 - Aug 2018\n\nAssisted investigators and researchers with data collection from laboratory experiments such as immunology staining experiments.\nAnalyzed &gt;2,000 data points using statistical analysis to determine the significance of research findings.\nWrote a 19-page report using graphs and charts to visualize and explain results derived from experiments.\n\n\n\nLab Research Assistant, The Barres Lab at Stanford University School of Medicine, Stanford, CA | Jul 2016 - Aug 2017\n\nCoded quantitative analysis script using MATLAB to calculate axon-to-myelin ratios from images of neurons.\nPrepared sagittal and coronal mice brain sections by operating a cryostat-microtome.\nAcknowledged in a publication in Cell."
  },
  {
    "objectID": "resume.html#leadership-activities",
    "href": "resume.html#leadership-activities",
    "title": "Resume",
    "section": "Leadership Activities",
    "text": "Leadership Activities\nPresident, Second Street Residence Hall Council (NYU) | Sept 2018 - Jan 2019\n\nCommunicated residence hall concerns to Hall Council committee during weekly presentations.\nCollaborated with Hall Council committee and residents to enhance residence hall experience through events."
  },
  {
    "objectID": "resume.html#awards",
    "href": "resume.html#awards",
    "title": "Resume",
    "section": "Awards",
    "text": "Awards\n\nPixelPlex Bi-Annual STEM Scholarship (Dec 2021)\n\nEssay Title: The Doctor is Always In: AI’s Possible Role in Mental Health\n\nDean’s List for Academic Year (Dec 2020)\n\nNew York University"
  },
  {
    "objectID": "resume.html#certificates",
    "href": "resume.html#certificates",
    "title": "Resume",
    "section": "Certificates",
    "text": "Certificates\n\nData Scientist Career Path (Sept 2021)\n\nCodecademy"
  },
  {
    "objectID": "sql.html",
    "href": "sql.html",
    "title": "SQL-Related Projects",
    "section": "",
    "text": "HackerRank SQL (Basic) Certificate"
  },
  {
    "objectID": "tableau.html",
    "href": "tableau.html",
    "title": "Tableau Projects",
    "section": "",
    "text": "See my Tableau visualizations on my Tableau Public profile here."
  },
  {
    "objectID": "writing.html",
    "href": "writing.html",
    "title": "Articles/Writing",
    "section": "",
    "text": "The Doctor is Always In: AI’s Possible Role in Mental Health"
  }
]